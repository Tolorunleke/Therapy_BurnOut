# -*- coding: utf-8 -*-
"""Tolorunleke @00714527

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XtZeorZSuHcl_8ROTnOmWF8VUg_Fy5rw
"""

# Commented out IPython magic to ensure Python compatibility.
#import library

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer
from sklearn import metrics
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.feature_selection import RFECV
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.neighbors import KNeighborsClassifier
# %matplotlib inline

#load dataset into python
therapy = pd.read_csv('Assignment_cleaned_datajeehp-20-27_dataset1_reviewed.csv')

#check for  null values
therapy.isna().values.any()

# shape of the dataset, total rows and total columns
therapy.shape

#first five rows of the data set to have idea of what we to work with
therapy.head(5)

#list columns with missing values
columns_with_missing_values = therapy.columns[therapy.isna().any()].tolist()
columns_with_missing_values

"""removing the column with reponse and nulls as they are just discription and not needed for the analysis"""

#drop the first row of the dataset, not needed as it holds no value of information
therapy= therapy.iloc[1:,:]

"""removing unwanted columns from the data set"""

therapy = therapy.drop(columns = ['index',
'Collector ID',
'Start Date',
'End Date'], axis = 1)

"""visualizing the most degree held by therapists"""

sns.countplot(therapy, x ='Highest_Degree')

"""check the dependant variable to see how unbalance the column is"""

therapy.iloc[:,-1].value_counts()

therapy['Post_Professional_Mentorship'].value_counts()

"""treat the missing value in the data set"""

#its more preffered to use the most_frequent for a classification feature
imputer = SimpleImputer(missing_values=np.nan, strategy= 'most_frequent', )
imputer = imputer.fit(therapy[['Post_Professional_Mentorship']])
new_sr = imputer.transform(therapy[['Post_Professional_Mentorship']])
new_sr

therapy['Post_Professional_Mentorship'] = new_sr

"""convert the whole columns to type int"""

therapy[['Active_licensed','Age','Gender','Race/Ethnicity','SOP','Rural/Urban','YOE',
'Employment_Status','Hours_Weekly','Settings(3yrs)','Type_of_Delivery','Highest_Degree'
,'HOCS','Professional_Certificates','Post_Professional_Mentorship','Work_health_Balance','Seeking_Challenge','Resignation_Mentality'
,'Work_Life_Imbalance','Work_as_Hindrance','Workplace_Defeatism','Health_Jeopardy','Career_Growth','Bad_Abilities_with_Difficulties'
,'Neglecting_Personal_Needs','Limited_work_Development','Work_Surrender','Problem_Solving_Confidence','Resourceful_Opposition'
,'Goal_Persistence','Crisis_Handling_Confidence','Resourceful_Adaptation','Effortful_Problem_Solving','Calm_Coping','Multiple_Solution_Orientation'
,'Troubleshoot_Thinking','Adaptive_Capability','Burned_Out'
        ]]= therapy[['Active_licensed','Age','Gender','Race/Ethnicity','SOP','Rural/Urban','YOE',
'Employment_Status','Hours_Weekly','Settings(3yrs)','Type_of_Delivery','Highest_Degree'
,'HOCS','Professional_Certificates','Post_Professional_Mentorship','Work_health_Balance','Seeking_Challenge','Resignation_Mentality'
,'Work_Life_Imbalance','Work_as_Hindrance','Workplace_Defeatism','Health_Jeopardy','Career_Growth','Bad_Abilities_with_Difficulties'
,'Neglecting_Personal_Needs','Limited_work_Development','Work_Surrender','Problem_Solving_Confidence','Resourceful_Opposition'
,'Goal_Persistence','Crisis_Handling_Confidence','Resourceful_Adaptation','Effortful_Problem_Solving','Calm_Coping','Multiple_Solution_Orientation'
,'Troubleshoot_Thinking','Adaptive_Capability','Burned_Out']].astype('int16')

#change the dependable varaible to 0 and 1
therapy['Burned_Out'] = therapy['Burned_Out'].map({1:0, 2:1})

"""confirm if the null values in the data set has been treated"""

therapy['Post_Professional_Mentorship'].isna().any()

"""taking therapist that are below the age of 21 out of the data set

"""

therapy['Age'] = therapy['Age'].astype('int64')
therapy = therapy[therapy['Age'] >= 21]
len(therapy)

#train test split the data
X = therapy.iloc[:,:37]
y = therapy.iloc[:,-1]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3,
                                                    random_state= 0, stratify = y)

"""Balancing the data set using the smote method"""

from imblearn.over_sampling import RandomOverSampler

resampler = SMOTE(random_state=0)
X_train, y_train = resampler.fit_resample(X_train,y_train)

sns.countplot(x= y_train)

# Use the SelectKBest selector from sklearn to select the k features with the best scores on a selected test statistic

selector = SelectKBest(f_classif, k=30)
X_train_fs = selector.fit_transform(X_train, y_train)
X_test_fs = selector.transform(X_test)

print(f'{X_train.shape[1]-X_train_fs.shape[1]} feature have been removed {X_train_fs.shape[1]} is left')

#standardising X for recursive feature selection
scaler = StandardScaler()
X_train_fs1 = scaler.fit_transform(X_train_fs)
X_test_fs1 = scaler.transform(X_test_fs)

#using the random forest libray as a base for feature selection
rf = RandomForestClassifier(random_state=0) # Use RandomForestClassifier as the base model

rfecv = RFECV(rf, cv=4, step=5)
X_train_fs2 = rfecv.fit_transform(X_train_fs1, y_train)
X_test_fs2 = rfecv.transform(X_test_fs1)
print(f'{X_train_fs.shape[1] - X_train_fs2.shape[1]} Removed Features {X_train_fs2.shape[1]} left Features')

#visualizing the result of the rfecv with the cv function that store the process of the cross validation
plt.figure( figsize=(15, 6))
plt.title('Number of Features Included vs Accuracy')
plt.xlabel('Number of Features Included')
plt.ylabel('Model Accuracy')
plt.plot(np.linspace(0,15,7), rfecv.cv_results_['mean_test_score'])
plt.show()

#the graph below goes to show the accuracy of our RFECV with 25 features we have start to have 78%
#from the 5th selection in otherword we need less than 5 features out of the 25 selected to accurately
#make prediction on the therapist classified to be 'Burned out or not

"""we have determined our set of data that has been scalled, feature selected using two methods and now ready to be used for diffect classes of data

setting up random forrest for the assignment
"""

rf_selectedfeatures = RandomForestClassifier()
rf_selectedfeatures.fit(X_train_fs2, y_train)

# Make predictions on the test data
y_pred_rf = rf_selectedfeatures.predict(X_test_fs2)
result = metrics.classification_report(y_test, y_pred_rf)
cm = metrics.confusion_matrix(y_test, y_pred_rf)

print(f"Accuracy Score: {accuracy_score(y_test,y_pred_rf)*100:.2f}%")
ax = sns.heatmap(cm, cmap='flare',annot=True, fmt='d')
plt.xlabel("Predicted Class",fontsize=12)
plt.ylabel("True Class",fontsize=12)
plt.title("Confusion Matrix",fontsize=12)
plt.show()



print('---------------------------------------------------')
print(result)
print('---------------------------------------------------')
print(cm,'\n\n')

y_train_pred = rf_selectedfeatures.predict(X_train_fs2)

y_test_pred = rf_selectedfeatures.predict(X_test_fs2)

train_accuracy = metrics.accuracy_score(y_train, y_train_pred)

test_accuracy = metrics.accuracy_score(y_test, y_test_pred)

print(train_accuracy, test_accuracy)







"""Using k neighbour for the classification"""

classifier = KNeighborsClassifier(n_neighbors=11, metric = 'minkowski', p = 2)
classifier.fit(X_train_fs2, y_train)

#check for the prediction of the X_test
y_pred = classifier.predict(X_test_fs2)
print(y_pred)

acc = metrics.accuracy_score(y_test, y_pred)
print(acc)

matrics = metrics.confusion_matrix(y_test, y_pred)
print(matrics)

report = metrics.classification_report(y_test, y_pred)
print('===============================================')
print(report)



boost = GradientBoostingClassifier(random_state=50)
boost.fit(X_train_fs2, y_train)

y_pred_boost = boost.predict(X_test_fs2)

metrics.accuracy_score(y_test, y_pred_boost)